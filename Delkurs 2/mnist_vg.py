import numpy as np
import pandas as pd
import joblib
from sklearn.datasets import fetch_openml
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import streamlit as st
from PIL import ImageOps, Image, ImageEnhance, ImageFilter, ImageDraw
from streamlit_drawable_canvas import st_canvas
import warnings
import matplotlib.pyplot as plt

# Ignorera UserWarnings relaterade till sklearn
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn.utils.validation")


def preprocess_image(image, contrast_factor):
    """
    F√∂rb√§ttrar en inmatad bild av en handritad siffra f√∂r MNIST-modellen.
    - Beh√•ller gr√•skala ist√§llet f√∂r h√•rd binarisering.
    - Justerar kontrast och sk√§rpa baserat p√• anv√§ndarens val.
    - S√§kerst√§ller 28x28 storlek.
    - Implementerar robust normalisering f√∂r att undvika division med noll.
    """
    if image is None:
        raise ValueError("Ingen bild har laddats in.")

    # 1Ô∏è‚É£ R√§tta till bildens orientering
    image = ImageOps.exif_transpose(image)

    # 2Ô∏è‚É£ Konvertera till gr√•skala
    gray_image = image.convert("L")

    # 3Ô∏è‚É£ Justera ljusstyrkan n√•got
    brightness_enhancer = ImageEnhance.Brightness(gray_image)
    brightened_image = brightness_enhancer.enhance(1.1)  # Mild ljusjustering

    # 4Ô∏è‚É£ √ñka kontrasten baserat p√• anv√§ndarens slider-inst√§llning
    contrast_enhancer = ImageEnhance.Contrast(brightened_image)
    contrast_image = contrast_enhancer.enhance(contrast_factor)

    # 5Ô∏è‚É£ Applicera Gaussian Blur f√∂r att mjuka upp konturer
    blurred_image = contrast_image.filter(ImageFilter.GaussianBlur(0.3))  # L√§tt blur

    # 6Ô∏è‚É£ Konvertera till NumPy-array f√∂r vidare bearbetning
    np_image = np.array(blurred_image, dtype=np.float32)

    # 7Ô∏è‚É£ Normalisering med skydd mot division med noll
    min_val = np.min(np_image)
    max_val = np.max(np_image)

    if max_val - min_val == 0:
        np_image = np.zeros_like(np_image, dtype=np.uint8)  # S√§tt alla pixlar till 0 (svart bild)
    else:
        np_image = np.clip(((np_image - min_val) / (max_val - min_val)) * 255, 0, 255)

    # 8Ô∏è‚É£ Se till att inga NaN eller inf-v√§rden finns
    np_image = np.nan_to_num(np_image)
    np_image = np_image.astype(np.uint8)

    # 9Ô∏è‚É£ Skapa bilden efter att den har normaliserats
    processed_image = Image.fromarray(np_image)

    # üîü Sk√§rp bilden l√§tt
    sharpness_enhancer = ImageEnhance.Sharpness(processed_image)
    final_image = sharpness_enhancer.enhance(1.3)  # Mild sk√§rpa

    # üîü Skala om till exakt 28x28 pixlar (MNIST-format)
    mnist_image = final_image.resize((28, 28))

    return mnist_image


# Steg 1: Ladda och preprocessa MNIST-data
def load_and_preprocess_mnist(subsample_percentage=100, test_size=0.2):
    if not (0 <= subsample_percentage <= 100):
        raise ValueError("subsample_percentage m√•ste vara mellan 0 och 100.")

    mnist = fetch_openml('mnist_784', version=1)
    X = pd.DataFrame(mnist.data / 255.0)  # Konvertera till DataFrame med kolumnnamn
    y = mnist.target.astype(int)

    if subsample_percentage < 100:
        X, _, y, _ = train_test_split(X, y, test_size=(1 - subsample_percentage / 100), random_state=42)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    return X_train, y_train, X_test, y_test


# Steg 2: Skapa pipelines f√∂r olika modeller
def get_pipelines():
    pipelines = {
        "Logistic Regression": Pipeline([
            ('scaler', StandardScaler()),
            ('model', LogisticRegression(max_iter=500, verbose=0))
        ]),
        "Random Forest": Pipeline([
            ('model', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, verbose=0))
        ]),
        "SVM": Pipeline([
            ('scaler', StandardScaler()),
            ('model', SVC(probability=True, kernel='rbf', C=10, gamma=0.001, verbose=False))
        ])
    }
    return pipelines


# Steg 3: Skapa en VotingClassifier
def create_voting_ensemble():
    pipelines = get_pipelines()
    voting_ensemble = VotingClassifier(estimators=[
        ('log_reg', pipelines["Logistic Regression"]),
        ('random_forest', pipelines["Random Forest"]),
        ('svm', pipelines["SVM"])
    ], voting='soft')
    return voting_ensemble


# Steg 4: Tr√§na modell
def train_model(model_name, X_train, y_train, optimize=False):
    if model_name == "Voting Ensemble":
        model = create_voting_ensemble()
        model.fit(X_train, y_train)
        joblib.dump(model, "voting_ensemble_model.pkl")
        st.write("Voting Ensemble √§r tr√§nad och sparad!")
        return

    pipelines = get_pipelines()
    pipeline = pipelines[model_name]

    if optimize:
        # üîπ Uppdaterade parameterrum f√∂r optimering
        param_distributions = {
            "Logistic Regression": {
                'model__C': [0.01, 0.1, 1, 10],  # Minskad lista med C-v√§rden
                'model__penalty': ['l2'],  # Endast l2-penalty
                'model__solver': ['lbfgs'],  # Snabb solver f√∂r Logistic Regression
                'model__max_iter': [500]  # Begr√§nsat till 500 iterationer
            },
            "SVM": {
                'model__C': [0.1, 1, 10, 100],  # Fler v√§rden f√∂r C
                'model__gamma': [0.001, 0.01, 0.1, 1],  # Fler gamma-v√§rden
                'model__kernel': ['rbf', 'linear']  # Ytterligare kernel
            },
            "Random Forest": {
                'model__n_estimators': [50, 100, 200, 300],  # Fler tr√§d
                'model__max_depth': [10, 20, 30, None],  # Fler maxdjup
                'model__min_samples_split': [2, 5, 10],  # Fler urval
                'model__bootstrap': [True, False],  # Bootstrap ja/nej
                'model__max_features': ['sqrt', 'log2']  # Ytterligare parameter
            }
        }

        # üîπ Begr√§nsa datasetet f√∂r optimering (25% av tr√§ningdatan)
        X_train_opt, _, y_train_opt, _ = train_test_split(
            X_train, y_train, test_size=0.25, random_state=42
        )

        # üîπ RandomizedSearchCV med f√∂rb√§ttrade inst√§llningar
        search = RandomizedSearchCV(
            pipeline,
            param_distributions[model_name],
            n_iter=20,  # Testa fler kombinationer
            cv=5,  # Fler korsvalideringsfolders
            n_jobs=-1,  # Anv√§nd alla CPU-k√§rnor
            random_state=42,
            verbose=10  # Visa f√∂rloppet
        )
        
        # üîπ Tr√§na med optimerad dataset
        search.fit(X_train_opt, y_train_opt)

        # üîπ Spara b√§sta modellen
        best_pipeline = search.best_estimator_
        joblib.dump(best_pipeline, f"{model_name.lower().replace(' ', '_')}_optimized_model.pkl")
        st.write(f"Optimerad {model_name} √§r tr√§nad och sparad!")
        st.write("B√§sta parametrar:")
        st.json(search.best_params_)

    else:
        pipeline.fit(X_train, y_train)
        joblib.dump(pipeline, f"{model_name.lower().replace(' ', '_')}_model.pkl")
        st.write(f"{model_name} √§r tr√§nad och sparad!")


# Steg 5: Ladda modell
def load_model(model_name, optimized=False):
    try:
        if model_name == "Voting Ensemble":
            model_file = "voting_ensemble_model.pkl"
        else:
            model_file = f"{model_name.lower().replace(' ', '_')}_optimized_model.pkl" if optimized else f"{model_name.lower().replace(' ', '_')}_model.pkl"
        model = joblib.load(model_file)
        return model
    except FileNotFoundError:
        st.error(f"Modellen {model_name} kunde inte laddas. Tr√§na modellen f√∂rst.")
        return None


# Steg 6: Utv√§rdera modell med f√∂rvirringsmatris
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    st.write(f"Modellens noggrannhet p√• testdata: {accuracy:.3f}")
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    st.pyplot(plt.gcf())


# Steg 7: Streamlit-applikation
def streamlit_app():
    st.title("MNIST Sifferigenk√§nning med Pipelines och Optimering")

    st.sidebar.header("Inst√§llningar")
    test_size = st.sidebar.slider("Andel testdata", min_value=0.1, max_value=0.5, step=0.1, value=0.2)
    subsample_percentage = st.sidebar.slider("Andel av datasetet att anv√§nda (%)", min_value=10, max_value=100, step=10, value=100)
    model_choice = st.sidebar.selectbox("V√§lj modell", ["Logistic Regression", "Random Forest", "SVM", "Voting Ensemble"])
    optimize = st.sidebar.checkbox("Optimering av hyperparametrar")
    use_optimized = st.sidebar.checkbox("Anv√§nd optimerad modell om tillg√§nglig")
    input_method = st.sidebar.radio("V√§lj inmatningsmetod", ["Rita p√• canvas", "Ladda upp bild"])

    # L√§gg till en slider i sidopanelen f√∂r kontrastjustering
    contrast_factor = st.sidebar.slider("Justera kontrast", min_value=0.5, max_value=4.0, step=0.1, value=2.5)

    # Ladda data
    X_train, y_train, X_test, y_test = load_and_preprocess_mnist(subsample_percentage=subsample_percentage, test_size=test_size)

    # Tr√§na modell
    if st.sidebar.button("Tr√§na modell"):
        train_model(model_choice, X_train, y_train, optimize=optimize)

    # Ladda vald modell
    model = load_model(model_choice, optimized=use_optimized)
    if model is None:
        return

    if use_optimized and model_choice != "Voting Ensemble":
        st.write(f"Optimerad {model_choice} laddades och anv√§nds f√∂r prediktion.")
    else:
        st.write(f"{model_choice} laddades och anv√§nds f√∂r prediktion.")

    # üîπ Titel f√∂r inmatningsmetod
    st.header("Inmatningsmetod")

    # üîπ Skapa kolumner f√∂r layout
    col1, col2 = st.columns(2)

    # üîπ Se till att `image` alltid existerar
    image = None  

    if input_method == "Rita p√• canvas":
        with col1:
            st.subheader("Rita en siffra")
            canvas_result = st_canvas(
                fill_color="#2E2E3E",
                stroke_width=10,
                stroke_color="Red",
                height=280,
                width=280,
                drawing_mode="freedraw",
                key="canvas"
            )
        if canvas_result.image_data is not None:
            image = Image.fromarray((canvas_result.image_data[:, :, 3] > 0).astype(np.uint8) * 255)

    elif input_method == "Ladda upp bild":
        with col1:
            st.subheader("Ladda upp en bild")
            uploaded_file = st.file_uploader("üìÇ Ladda upp en bild h√§r:", type=["png", "jpg", "jpeg"])

        if uploaded_file is not None:
            st.write("‚úÖ Fil laddad:", uploaded_file.name)
            image = Image.open(uploaded_file)

    # üîπ Om ingen bild finns, visa varning och stoppa koden
    if image is None:
        st.warning("‚ö†Ô∏è Ingen bild har laddats upp eller ritats! Ladda upp en fil ovan.")
        st.stop()

    # ‚úÖ F√∂rb√§ttra och f√∂rbered bilden (R√ÑTT INDENTERAT!)
    processed_image = preprocess_image(image, contrast_factor)  # ‚úÖ Skickar med kontrastv√§rdet

    with col2:
        st.image(processed_image.resize((280, 280)), caption="F√∂rb√§ttrad & Normaliserad Bild", use_container_width=True)

    # üîπ Konvertera till MNIST-format
    data = (np.array(processed_image) / 255.0).reshape(1, -1)
    data = pd.DataFrame(data, columns=X_train.columns)

    # ‚úÖ Kontrollera att modellen existerar innan prediktion
    if model is None:
        st.error("‚ùå Ingen modell √§r laddad! Tr√§na modellen f√∂rst.")
        st.stop()

    # üîπ G√∂r prediktion
    prediction = model.predict(data)
    probabilities = model.predict_proba(data)
    st.write(f"Modellen f√∂ruts√§ger: {prediction[0]}")

    # üîπ Visa sannolikhetsdiagram
    chart_data = pd.DataFrame(probabilities[0], columns=["Probability"], index=list(range(10)))
    st.bar_chart(chart_data, use_container_width=True)

    # üîπ Utv√§rdera modellen p√• testdata
    if st.sidebar.button("Utv√§rdera modell"):
        st.header("Utv√§rdering av modell")
        evaluate_model(model, X_test, y_test)


if __name__ == "__main__":
    streamlit_app()
